{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "869455cf",
   "metadata": {},
   "source": [
    "### Loading the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a373c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score,recall_score,precision_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7096a36",
   "metadata": {},
   "source": [
    "### Loading the new unseen dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45328eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values:\n",
      "Dis No                                 0\n",
      "Year                                   0\n",
      "Seq                                    0\n",
      "Glide                              13063\n",
      "Disaster Group                         0\n",
      "Disaster Subgroup                      0\n",
      "Disaster Type                          0\n",
      "Disaster Subtype                    2747\n",
      "Disaster Subsubtype                13600\n",
      "Event Name                         10999\n",
      "Country                                0\n",
      "ISO                                    0\n",
      "Region                                 0\n",
      "Continent                              0\n",
      "Location                            1346\n",
      "Origin                             10864\n",
      "Associated Dis                     11412\n",
      "Associated Dis2                    13946\n",
      "OFDA Response                      13194\n",
      "Appeal                             12204\n",
      "Declaration                        11517\n",
      "Aid Contribution                   13967\n",
      "Dis Mag Value                      10075\n",
      "Dis Mag Scale                       1073\n",
      "Latitude                           12313\n",
      "Longitude                          12309\n",
      "Local Time                         13879\n",
      "River Basin                        13359\n",
      "Start Year                             0\n",
      "Start Month                          268\n",
      "Start Day                           3067\n",
      "End Year                               0\n",
      "End Month                            549\n",
      "End Day                             2994\n",
      "Total Deaths                        4445\n",
      "No Injured                         10993\n",
      "No Affected                         5798\n",
      "No Homeless                        12395\n",
      "Total Affected                      3603\n",
      "Reconstruction Costs ('000 US$)    14613\n",
      "Insured Damages ('000 US$)         13550\n",
      "Total Damages ('000 US$)            9781\n",
      "CPI                                  315\n",
      "Adm Level                           6789\n",
      "Admin1 Code                        10063\n",
      "Admin2 Code                        10679\n",
      "Geo Locations                       6789\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "new_data = pd.read_csv('new_unseen_dataset.csv')\n",
    "\n",
    "# Checking for Missing values\n",
    "print(\"Null values:\")\n",
    "print(new_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6206301e",
   "metadata": {},
   "source": [
    "### Preprocessing the new unseen dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a0c9ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data.replace('nan', np.nan, inplace=True)\n",
    "\n",
    "numerical_cols = new_data.select_dtypes(include=np.number).columns\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "new_data[numerical_cols] = imputer.fit_transform(new_data[numerical_cols])\n",
    "\n",
    "categorical_cols = new_data.select_dtypes(include='object').columns\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "new_data[categorical_cols] = imputer.fit_transform(new_data[categorical_cols])\n",
    "\n",
    "# Label encoding for categorical variables\n",
    "label_encoder = LabelEncoder()\n",
    "for col in categorical_cols:\n",
    "    new_data[col] = label_encoder.fit_transform(new_data[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4504ce76",
   "metadata": {},
   "source": [
    "### Feature Selection and Engineering - based on domain and mutal knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ab8aeb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Dis Mag Scale</th>\n",
       "      <th>Dis Mag Value</th>\n",
       "      <th>Country</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Disaster Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1970.0</td>\n",
       "      <td>0</td>\n",
       "      <td>50935.321952</td>\n",
       "      <td>7</td>\n",
       "      <td>2039</td>\n",
       "      <td>1113</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1970.0</td>\n",
       "      <td>1</td>\n",
       "      <td>50935.321952</td>\n",
       "      <td>9</td>\n",
       "      <td>2039</td>\n",
       "      <td>1113</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1970.0</td>\n",
       "      <td>0</td>\n",
       "      <td>50935.321952</td>\n",
       "      <td>20</td>\n",
       "      <td>2039</td>\n",
       "      <td>1113</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1970.0</td>\n",
       "      <td>1</td>\n",
       "      <td>50935.321952</td>\n",
       "      <td>15</td>\n",
       "      <td>2039</td>\n",
       "      <td>1113</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1970.0</td>\n",
       "      <td>1</td>\n",
       "      <td>50935.321952</td>\n",
       "      <td>15</td>\n",
       "      <td>2039</td>\n",
       "      <td>1113</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1970.0</td>\n",
       "      <td>0</td>\n",
       "      <td>50935.321952</td>\n",
       "      <td>15</td>\n",
       "      <td>2039</td>\n",
       "      <td>1113</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1970.0</td>\n",
       "      <td>1</td>\n",
       "      <td>50935.321952</td>\n",
       "      <td>15</td>\n",
       "      <td>2039</td>\n",
       "      <td>1113</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1970.0</td>\n",
       "      <td>0</td>\n",
       "      <td>50935.321952</td>\n",
       "      <td>26</td>\n",
       "      <td>2039</td>\n",
       "      <td>1113</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1970.0</td>\n",
       "      <td>0</td>\n",
       "      <td>50935.321952</td>\n",
       "      <td>26</td>\n",
       "      <td>2039</td>\n",
       "      <td>1113</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1970.0</td>\n",
       "      <td>0</td>\n",
       "      <td>50935.321952</td>\n",
       "      <td>16</td>\n",
       "      <td>2039</td>\n",
       "      <td>1113</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year  Dis Mag Scale  Dis Mag Value  Country  Longitude  Latitude  \\\n",
       "0  1970.0              0   50935.321952        7       2039      1113   \n",
       "1  1970.0              1   50935.321952        9       2039      1113   \n",
       "2  1970.0              0   50935.321952       20       2039      1113   \n",
       "3  1970.0              1   50935.321952       15       2039      1113   \n",
       "4  1970.0              1   50935.321952       15       2039      1113   \n",
       "5  1970.0              0   50935.321952       15       2039      1113   \n",
       "6  1970.0              1   50935.321952       15       2039      1113   \n",
       "7  1970.0              0   50935.321952       26       2039      1113   \n",
       "8  1970.0              0   50935.321952       26       2039      1113   \n",
       "9  1970.0              0   50935.321952       16       2039      1113   \n",
       "\n",
       "   Disaster Type  \n",
       "0              5  \n",
       "1             11  \n",
       "2              5  \n",
       "3             11  \n",
       "4             11  \n",
       "5              5  \n",
       "6             11  \n",
       "7              1  \n",
       "8              5  \n",
       "9              5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature selection using mutual information\n",
    "selected_features = ['Year', 'Dis Mag Scale', 'Dis Mag Value', 'Country', 'Longitude', 'Latitude', 'Disaster Type']\n",
    "X_selected = new_data[selected_features]\n",
    "\n",
    "# Saving the selected features into a new CSV file\n",
    "X_selected.to_csv('new_unseen_preprocessed_data.csv', index=False)\n",
    "\n",
    "# Loading the preprocessed_data.csv file\n",
    "new_data_selected = pd.read_csv('new_unseen_preprocessed_data.csv')\n",
    "\n",
    "# Displaying the first 10 rows of the loaded data\n",
    "new_data_selected.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ab5454",
   "metadata": {},
   "source": [
    "### Testing the Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e62c79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "# Load the oversampler and the trained Random Forest model\n",
    "\n",
    "loaded_model = joblib.load('random_forest_model.joblib')\n",
    "\n",
    "# Assuming 'new_data.csv' is your new, unseen data\n",
    "new_data = pd.read_csv('new_unseen_preprocessed_data.csv')\n",
    "\n",
    "# Separate feature set and target variable\n",
    "X_new = new_data.drop('Disaster Type', axis=1)\n",
    "y_new = new_data['Disaster Type']\n",
    "\n",
    "oversampler = RandomOverSampler()\n",
    "X_new_resampled, y_new_resampled = oversampler.fit_resample(X_new, y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92cbb932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      5272\n",
      "           1       0.90      0.90      0.90      5272\n",
      "           2       1.00      1.00      1.00      5272\n",
      "           3       1.00      1.00      1.00      5272\n",
      "           4       1.00      1.00      1.00      5272\n",
      "           5       0.99      0.75      0.85      5272\n",
      "           6       1.00      1.00      1.00      5272\n",
      "           7       1.00      1.00      1.00      5272\n",
      "           8       0.94      0.98      0.96      5272\n",
      "           9       0.84      0.85      0.84      5272\n",
      "          10       0.93      1.00      0.96      5272\n",
      "          11       1.00      1.00      1.00      5272\n",
      "          12       0.91      0.98      0.94      5272\n",
      "          13       0.91      0.96      0.94      5272\n",
      "\n",
      "    accuracy                           0.96     73808\n",
      "   macro avg       0.96      0.96      0.96     73808\n",
      "weighted avg       0.96      0.96      0.96     73808\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_new_resampled, y_new_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardizing/Scaling the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Standardizing/Scaling the features using the previously defined scaler\n",
    "X_new_scaled = scaler.transform(X_new_resampled)\n",
    "\n",
    "# Training the Random Forest model on the resampled data\n",
    "loaded_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Making predictions using the trained model\n",
    "predictions = loaded_model.predict(X_test_scaled)\n",
    "\n",
    "#print(\"Classification Report on Test Set:\")\n",
    "#print(classification_report(y_test, predictions))\n",
    "\n",
    "# Making predictions on the whole resampled dataset\n",
    "predictions_full = loaded_model.predict(X_new_scaled)\n",
    "\n",
    "print(\"\\nClassification Report\")\n",
    "print(classification_report(y_new_resampled, predictions_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9cd965",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
